{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling Report\n",
    "\n",
    "*Project #2 - Data Wrangling report prepared by `Augustine Phiri`*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data for this project excirse 2 was gathered from WeRateDogs twitter archive with the purpose of practicing a typical wrangling process for easy and clean analysis and visualization of the data. \n",
    "\n",
    "This report will be within 300 - 600 words, and its name will either be wrangle_report.pdf or wrangle_report.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> I downloaded WeRateDogs Twitter archive data file `twitter-archive-enhanced.csv` manually from `https://d17h27t6h515a5.cloudfront.net/topher/2017/August/59a4e958_twitter-archive-enhanced/twitter-archive-enhanced.csv` URL which was provide in the classroom to my working project directory link, which was provided in the udacity classroom as one of the instructions for completing this project `two`. After downloading the file, I palced it in my working project directory and used `pd.read_csv('twitter_archive_enhanced.csv')` to load it to a Pandas DataFrame in a jupter notebook..\n",
    "\n",
    "> Secondly I downloaded the file `image-predictions.tsv` pragrammatically using the Request Library from URL provided in the classroom. After downlaoding the file, I loaded it in the jupter notebook using pandas function `pd.read_csv('file_name', sep='\\t'). And then, I saved the file as `.CSV file`. \n",
    "image-predictions.tsv I then proceeded to programmatically download the 599fd2ad_image-predictions/image-predictions.tsv file using the Request Library from the URL provided by Udacity.\n",
    "\n",
    "> Lastly, Json data `data_json.txt file` was downloaded manually in the udacity classroom. After downloading, the file was read into the jupter notebook line by line to pandas Dataframe with tweet id, favorite count and retweet count."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Assessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> I assessed my data using both vissual and programmatical ways. To assess my data vissually I used the function `head()` to visualize and glance at the data, and `sample()`and programmatically I used different functions like `info()`, `dtypes`, `description()`, `isnull()` etc. After both vissual and programmatic assessment, at least eight (8) data quality issues and two (2) tidiness issues ware detected, and included the issues to clean to satisfy the Project Motivation. Each issue was documented in one to a few sentences each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Completeness\n",
    "\n",
    "1. Missing values in several columns of df_archive dataframe\n",
    "\n",
    "### Validity\n",
    "\n",
    "2. Values are presented as hyperliks insted of URLs in 'source' column of archive dataframe\n",
    "\n",
    "3. 'expanded_urls' column in archive dataframe have some missing values\n",
    "\n",
    "### Accurancy\n",
    "\n",
    "4. image predictions dataframe has Non-descriptive column name such as p1, p1_conf, p1_dog, p2, p2_conf, p2_dog, p3, p3_conf, p3_dog)\n",
    "\n",
    "5. Dataset contains data beyond 08/01/2017\n",
    "\n",
    "6. Erroneous data types (tweet_id, in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id, and retweeted_status_timestamp)\n",
    "\n",
    "### Consistancy\n",
    "\n",
    "7. Some names have underscores, and are starting with capital letters in ('p1', 'p2', and 'p3' columns)\n",
    "\n",
    "8. Some dog names in a 'name' column of archive are set to articles('a', 'an', and 'the')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidiness issues\n",
    "\n",
    "1. df_archive data table needs to be merged with extracted_data table, and then merge with image predition dataset\n",
    "\n",
    "2. Archive dataframe has four columns namely; doggo, floofer, pupper, puppo which are for a single variable dog stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> I completed all the cleaning steps using the programmatic process of cleaning data. In each step, i was able to define, executed the code, and test if the code worked successfully. Once I had completed the cleaning and tideness of the archive dataframe I created a new dataframe called df_archive_clean and save it into a new file `twitter_archive_master.csv`.\n",
    "\n",
    "> After completing the cleaning process, the data was successfully stored. I saved the df_archive_clean dataframe into a twitter_archive_master.csv file . I confirmed visually that the file was saved successfuly and then I used it for analysis and visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Analysis and Visualizing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> After clearning the dataframe, I was able to analyse data and generated graphs to visually present the data. I used `scatter` plots and `bar` plot types of graphs using libraries such as matplotlib."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
